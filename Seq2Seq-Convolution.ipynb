{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.conv_seq2seq import *\n",
    "from src.utils import *\n",
    "from src.layers import MaskedCrossEntropyLoss\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONS: \n",
    "# ENGLISH - en, \n",
    "# GERMAN - de, \n",
    "# FRENCH - fr, \n",
    "# CZECH - cs\n",
    "\n",
    "lang1 = 'de'\n",
    "lang2 = 'en'\n",
    "\n",
    "train_sentences, test_sentences = load_data(lang1, lang2)\n",
    "train_sentences = (train_sentences[0][:500], train_sentences[1][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE=0.2\n",
    "BATCH_SIZE=64\n",
    "VALID_BATCH_SIZE=128\n",
    "MAX_VOCAB=20000\n",
    "\n",
    "src_vocab, tgt_vocab, train_loader, valid_loader = make_dataset(train_sentences, test_sentences, BATCH_SIZE, VALID_BATCH_SIZE, MAX_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 500\n",
      "Number of validation examples: 1014\n",
      "Training Batches 8\tValidation Batches 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of validation examples: {len(valid_loader.dataset)}\")\n",
    "print(f\"Training Batches {len(train_loader)}\\tValidation Batches {len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 1348\n",
      "Unique tokens in target (en) vocabulary: 1224\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source ({lang1}) vocabulary: {len(src_vocab)}\")\n",
    "print(f\"Unique tokens in target ({lang2}) vocabulary: {len(tgt_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER ARGS\n",
    "ENC_UNITS = 32 # 512\n",
    "ENC_EMBEDDING = 32 # 256\n",
    "SRC_VOCAB_SIZE = len(src_vocab)\n",
    "ENC_NUM_LAYERS = 10 # 10\n",
    "ENC_KERNEL_SIZE = 3 # ODD\n",
    "DROPOUT = 0.25\n",
    "\n",
    "# DECODER ARGS\n",
    "DEC_UNITS = ENC_UNITS\n",
    "DEC_EMBEDDING = ENC_EMBEDDING\n",
    "TGT_VOCAB_SIZE = len(tgt_vocab)\n",
    "DEC_NUM_LAYERS = ENC_NUM_LAYERS\n",
    "DEC_KERNEL_SIZE = 3 # EVEN OR ODD\n",
    "PAD_IDX = tgt_vocab.PAD_token\n",
    "\n",
    "\n",
    "# SEQ2SEQ ARGS\n",
    "MAX_LENGTH = max(train_loader.dataset.tensors[1].size(1), train_loader.dataset.tensors[0].size(1)) + 3\n",
    "SOS_TOKEN = tgt_vocab.SOS_token\n",
    "TEACHER_FORCING = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 256,328 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(SRC_VOCAB_SIZE, ENC_EMBEDDING, ENC_UNITS, ENC_NUM_LAYERS, ENC_KERNEL_SIZE, DROPOUT, MAX_LENGTH)\n",
    "decoder = Decoder(DEC_UNITS, DEC_EMBEDDING, TGT_VOCAB_SIZE, DEC_NUM_LAYERS, DEC_KERNEL_SIZE, DROPOUT, PAD_IDX, MAX_LENGTH)\n",
    "\n",
    "seq2seq = Seq2Seq(encoder, decoder, TEACHER_FORCING, MAX_LENGTH, SOS_TOKEN)\n",
    "\n",
    "print(f'The model has {count_parameters(seq2seq):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (token_embedding): Embedding(1348, 32)\n",
      "    (position_embedding): Embedding(49, 32)\n",
      "    (embed2hidden): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (hidden2embed): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (convs): Sequential(\n",
      "      (0): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (1): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (2): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (3): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (4): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (5): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (6): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (7): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (8): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "      (9): EncoderConv(\n",
      "        (conv): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "        (dropout): Dropout(p=0.25, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (token_embedding): Embedding(1224, 32)\n",
      "    (position_embedding): Embedding(49, 32)\n",
      "    (embedd2hidden): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (hidden2embedd): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (attention_layer): Attention(\n",
      "      (hidden2embed): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (embed2hidden): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (decoder_conv): DecoderConv(\n",
      "      (dropout): Dropout(p=0.25, inplace=False)\n",
      "    )\n",
      "    (convs): ModuleList(\n",
      "      (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (1): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (2): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (4): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (5): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (6): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (7): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (8): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "      (9): Conv1d(32, 64, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "    (out): Linear(in_features=32, out_features=1224, bias=True)\n",
      "    (dropout): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(seq2seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MaskedCrossEntropyLoss(pad_tok=tgt_vocab.PAD_token)\n",
    "optimizer = optim.Adam(seq2seq.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# valid_loss = evaluate(seq2seq, valid_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   5,  12,   8,   7, 177,  70,  26,  19, 117, 579, 148,   6,  16,\n",
      "         300,  18, 177, 151,   3]])\n",
      "tensor([[  3,   2,   9,   6,   2, 139,  10,  77, 345,  16, 135, 592,  14, 317,\n",
      "          81,   6,   2, 139,   5,   4]])\n",
      "torch.Size([1, 20]) torch.Size([1, 20])\n",
      "['<sos> ein mann in einem anzug rennt an zwei anderen herren vorbei , die auch einen anzug tragen . <eos>']\n",
      "['<sos> a man in a suit is running past two other gentleman , also dressed in a suit . <eos>']\n"
     ]
    }
   ],
   "source": [
    "idx = 55\n",
    "src_sentence = train_loader.dataset.tensors[0][idx:idx+1][:, :20]\n",
    "tgt_sentence = train_loader.dataset.tensors[1][idx:idx+1][:, :20]\n",
    "print(src_sentence[:, :19])\n",
    "print(tgt_sentence[:, :21])\n",
    "print(src_sentence.size(), tgt_sentence.size())\n",
    "print(src_vocab.to_string(src_sentence))\n",
    "print(tgt_vocab.to_string(tgt_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, attention = seq2seq(src_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 49, 1224]), torch.Size([1, 49, 20]))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(), attention.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'someone paintbrush sweatshirt wearing hide jars adults top wearing river barefooted noddles jars someone gathering noddles jars covered police noddles adults skirt police wearing jars noddles hide toy someone having heavy she wearing flowers gathering police wedding heavy adults clutch skirt noddles surprised red lays adults adults jars leading'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation = tgt_vocab.to_string(out.argmax(dim=-1))[0]\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▎        | 1/8 [00:08<00:57,  8.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 2/8 [00:14<00:44,  7.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:19<00:34,  6.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:27<00:28,  7.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:36<00:23,  7.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:43<00:14,  7.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 7/8 [00:49<00:07,  7.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 8/8 [00:54<00:00,  6.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▎        | 1/8 [00:01<00:13,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 2/8 [00:03<00:11,  1.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:05<00:09,  1.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:07<00:07,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:09<00:05,  1.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:11<00:03,  1.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 7/8 [00:13<00:01,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 8/8 [00:15<00:00,  1.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\tTrain Loss: 7.077 | Train PPL: 1184.509\n",
      "\t Val. Loss: 6.943 |  Val. PPL: 1035.859\n",
      "Epoch: 02\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▎        | 1/8 [00:07<00:51,  7.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 2/8 [00:13<00:42,  7.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:20<00:34,  6.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:25<00:26,  6.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-10717e762a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1:02}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_vocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPAD_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Attention/src/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, pad_tok)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "CLIP = 1\n",
    "\n",
    "# seq2seq.teacher_forcing = 1.0\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    \n",
    "    train_loss = train(seq2seq, train_loader, optimizer, criterion, CLIP, src_vocab.PAD_token)\n",
    "    valid_loss = evaluate(seq2seq, train_loader, criterion)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(seq2seq.state_dict(), 'models/seq2seq_conv.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translate(model, iterator, criterion, pad_tok=0):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (src, tgt) in enumerate(tqdm(iterator, file=sys.stdout)):\n",
    "            # src.shape = (batch_size, src_seq_len)\n",
    "            # tgt.shape = (batch_size, tgt_seq_len)\n",
    "            src_mask = create_padding_mask(src, pad_tok)\n",
    "\n",
    "            if model.type == 'rnn':\n",
    "                output, attention = model(src, None, src_mask) #turn off teacher forcing\n",
    "                # output.shape == (batch_size, max_length, tgt_vocab_size)\n",
    "                # print(output)\n",
    "                # output = output[:, 1:, :]\n",
    "                tgt = tgt[:, 1:]\n",
    "            elif model.type == 'conv':\n",
    "                output, attention = model(src, None) #turn off teacher forcing\n",
    "                tgt = tgt[:, 1:]\n",
    "\n",
    "            loss = criterion(output, tgt) # masked loss automatically slices for you\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█▎        | 1/8 [00:03<00:21,  3.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 2/8 [00:06<00:19,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███▊      | 3/8 [00:09<00:16,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 4/8 [00:13<00:12,  3.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:16<00:09,  3.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:19<00:06,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████▊ | 7/8 [00:22<00:03,  3.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 8/8 [00:25<00:00,  2.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "valid_loss = evaluate_translate(seq2seq, train_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8958491086959839, 2.4494147260598007)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loss, math.exp(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "src_sentence = train_loader.dataset.tensors[0][idx:idx+1]\n",
    "tgt_sentence = train_loader.dataset.tensors[1][idx:idx+1]\n",
    "\n",
    "src_sentence = src_vocab.to_string(src_sentence, remove_special=True)[0]\n",
    "tgt_sentence = tgt_vocab.to_string(tgt_sentence, remove_special=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,  19,  21,  29,  32,  35, 146,  17,  57,   8,  15,  58, 478, 479,\n",
      "           3,   4]])\n",
      "tensor([[35, 22,  5,  4,  5,  4,  5,  5,  4,  5,  5,  4,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4]])\n"
     ]
    }
   ],
   "source": [
    "translation, attention = translate(src_sentence, seq2seq, src_vocab, tgt_vocab, src_vocab.PAD_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> zwei junge wei e manner sind im freien in der nahe vieler busche .\n",
      "= two young , white males are outside near many bushes .\n",
      "< men boy . . . . . .\n"
     ]
    }
   ],
   "source": [
    "print(f\"> {src_sentence}\")\n",
    "print(f\"= {tgt_sentence}\")\n",
    "print(f\"< {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab.PAD_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention(attention, src_sentence, translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3664e-11, 1.0312e-04, 1.2130e-21, 3.2909e-11, 1.0098e-01, 4.4736e-09,\n",
       "         1.2194e-10, 8.9715e-10, 2.9493e-08, 2.2802e-06, 3.1995e-07, 1.0730e-09,\n",
       "         5.1280e-10, 8.9890e-01, 1.6924e-05],\n",
       "        [1.2821e-07, 2.2048e-11, 2.5935e-09, 8.2775e-04, 9.6637e-01, 1.8144e-03,\n",
       "         3.6247e-08, 2.3610e-04, 2.4396e-05, 4.4837e-04, 2.9789e-02, 6.7302e-11,\n",
       "         3.1570e-04, 1.6431e-04, 1.5167e-10],\n",
       "        [9.7672e-09, 6.2471e-34, 8.9530e-07, 1.5813e-14, 3.4575e-20, 6.9667e-19,\n",
       "         5.8963e-15, 1.4152e-18, 6.0852e-06, 5.0482e-12, 5.8400e-28, 2.9403e-39,\n",
       "         4.2869e-13, 4.5173e-11, 9.9999e-01],\n",
       "        [3.0974e-24, 6.0256e-44, 0.0000e+00, 3.3918e-30, 1.8024e-25, 8.6161e-30,\n",
       "         1.4547e-22, 8.9977e-25, 8.0511e-24, 3.4063e-20, 2.0275e-40, 0.0000e+00,\n",
       "         2.0891e-32, 7.1727e-18, 1.0000e+00],\n",
       "        [8.9777e-29, 0.0000e+00, 0.0000e+00, 1.0618e-32, 7.0668e-37, 3.0974e-39,\n",
       "         2.0014e-30, 1.1380e-33, 3.5251e-30, 6.0993e-26, 0.0000e+00, 0.0000e+00,\n",
       "         2.3035e-35, 5.8863e-25, 1.0000e+00],\n",
       "        [2.3068e-19, 4.8090e-38, 3.3242e-25, 2.0777e-25, 3.3061e-21, 2.7908e-20,\n",
       "         6.0246e-17, 6.1876e-18, 2.0184e-16, 6.0058e-17, 2.6551e-38, 1.3525e-38,\n",
       "         1.3364e-22, 6.1765e-14, 1.0000e+00],\n",
       "        [8.2927e-30, 0.0000e+00, 1.0650e-43, 5.6893e-43, 3.6814e-37, 9.4699e-40,\n",
       "         8.1805e-32, 9.7110e-43, 7.0610e-33, 3.0667e-29, 0.0000e+00, 0.0000e+00,\n",
       "         4.9073e-42, 9.9286e-27, 1.0000e+00],\n",
       "        [1.7403e-34, 0.0000e+00, 0.0000e+00, 6.4268e-36, 2.4191e-38, 3.8271e-40,\n",
       "         9.1159e-36, 8.5954e-36, 2.3243e-34, 9.2645e-31, 0.0000e+00, 0.0000e+00,\n",
       "         3.6189e-35, 2.3873e-29, 1.0000e+00],\n",
       "        [3.4026e-24, 0.0000e+00, 4.6494e-41, 8.7443e-31, 1.4758e-29, 2.8305e-26,\n",
       "         1.1087e-22, 1.4599e-26, 4.6644e-25, 4.3344e-21, 0.0000e+00, 0.0000e+00,\n",
       "         2.4369e-28, 3.8863e-21, 1.0000e+00],\n",
       "        [7.2791e-26, 0.0000e+00, 0.0000e+00, 5.7198e-35, 4.6198e-23, 1.2014e-27,\n",
       "         6.7704e-24, 1.3433e-34, 4.1503e-28, 9.9995e-23, 0.0000e+00, 0.0000e+00,\n",
       "         5.7066e-35, 1.3590e-19, 1.0000e+00],\n",
       "        [4.1151e-18, 0.0000e+00, 1.0594e-40, 2.1315e-20, 1.4336e-18, 4.9150e-23,\n",
       "         3.3135e-21, 4.9244e-29, 6.3122e-21, 2.0393e-16, 3.4520e-37, 0.0000e+00,\n",
       "         2.1744e-24, 4.4342e-12, 1.0000e+00],\n",
       "        [5.6816e-08, 5.4527e-28, 1.4655e-21, 4.3951e-15, 6.6437e-12, 3.0120e-08,\n",
       "         2.8635e-10, 1.2669e-12, 5.1030e-11, 2.2638e-11, 4.8484e-25, 1.0053e-30,\n",
       "         8.9869e-15, 2.1033e-10, 1.0000e+00],\n",
       "        [1.2865e-09, 5.1973e-26, 5.4466e-28, 1.7447e-09, 9.3543e-07, 2.9193e-06,\n",
       "         3.2103e-05, 1.4485e-15, 2.0995e-08, 1.6247e-04, 6.5196e-15, 3.5046e-13,\n",
       "         6.7415e-10, 1.8600e-03, 9.9794e-01],\n",
       "        [1.5411e-12, 0.0000e+00, 1.5144e-33, 4.3780e-17, 6.9040e-06, 3.3462e-05,\n",
       "         3.4974e-12, 2.5646e-23, 7.8245e-13, 4.3299e-07, 8.5575e-28, 3.9998e-37,\n",
       "         2.3091e-14, 2.6916e-09, 9.9996e-01],\n",
       "        [9.7063e-12, 7.9140e-34, 1.9793e-23, 1.7953e-16, 1.8471e-04, 1.0775e-03,\n",
       "         3.2006e-04, 3.7588e-18, 6.5243e-06, 3.3335e-04, 9.8744e-20, 5.0934e-21,\n",
       "         1.0955e-11, 2.0120e-04, 9.9787e-01],\n",
       "        [2.8021e-06, 9.0713e-32, 1.1168e-22, 1.8852e-14, 1.1319e-01, 1.1720e-02,\n",
       "         2.1453e-04, 6.4433e-18, 2.3271e-08, 8.9521e-04, 9.1683e-21, 7.6099e-21,\n",
       "         1.1816e-11, 1.4260e-04, 7.9278e-02],\n",
       "        [8.0943e-14, 7.0001e-35, 1.4653e-29, 8.9785e-24, 5.8065e-05, 2.2452e-07,\n",
       "         1.7462e-07, 1.6474e-21, 2.5989e-08, 1.2256e-07, 1.2523e-28, 6.6775e-30,\n",
       "         7.8331e-20, 6.9065e-05, 9.9987e-01],\n",
       "        [3.3781e-09, 1.3491e-24, 3.4482e-19, 8.4912e-15, 7.3255e-03, 9.1698e-01,\n",
       "         1.0905e-02, 5.3986e-15, 1.5105e-04, 1.2166e-02, 2.3862e-16, 1.9585e-13,\n",
       "         5.3369e-11, 7.5445e-04, 7.6128e-03],\n",
       "        [8.1737e-13, 2.8891e-40, 1.3668e-35, 1.2314e-16, 3.9472e-08, 1.2538e-09,\n",
       "         1.2303e-09, 2.8127e-21, 5.3179e-12, 2.5695e-06, 1.8739e-24, 2.2983e-28,\n",
       "         3.9401e-15, 1.8168e-07, 1.0000e+00],\n",
       "        [4.3195e-14, 0.0000e+00, 1.2439e-35, 3.3654e-19, 1.6771e-05, 6.3347e-06,\n",
       "         2.4489e-10, 1.8349e-29, 8.3886e-11, 2.3264e-06, 1.0960e-30, 8.6905e-40,\n",
       "         6.5156e-18, 1.5489e-09, 9.9997e-01],\n",
       "        [1.1387e-12, 0.0000e+00, 1.5134e-38, 2.2658e-20, 6.2496e-04, 3.4097e-05,\n",
       "         3.4529e-06, 2.3623e-29, 1.8058e-09, 2.1305e-04, 7.1624e-36, 1.6118e-38,\n",
       "         2.9068e-17, 7.5757e-05, 9.9904e-01],\n",
       "        [3.7863e-12, 0.0000e+00, 5.6596e-38, 3.0210e-23, 5.0268e-02, 1.4052e-04,\n",
       "         4.8416e-05, 1.1508e-25, 2.0864e-10, 3.0742e-03, 7.0394e-35, 6.5402e-38,\n",
       "         5.3996e-17, 3.1992e-07, 9.4647e-01],\n",
       "        [6.3822e-10, 0.0000e+00, 8.3255e-29, 1.0268e-20, 3.7128e-07, 2.8149e-06,\n",
       "         1.1815e-06, 1.6982e-25, 1.3850e-07, 6.2953e-05, 6.2972e-33, 2.3921e-36,\n",
       "         5.5318e-16, 7.5934e-08, 9.9990e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_loss = evaluate(seq2seq, valid_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
